We start off by considering GPs with constant mean function and squared exponential kernel, whose mean and kernel functions are related to the hyperparameters $c$, $k$, and $\lambda$ as follows ($\sigma$ is also considered to be a hyperparameter, although it is not explicitly part of the mean or kernel functions):
% Equation: constant mean and squared exponential kernel function
\begin{align}
\mu(x) &= c \\
K_{\text{sqe}}(x, x') &= k \exp\left( -\left( \frac{x - x'}{\lambda} \right)^2 \right) \label{eq:sqe kernel}
\end{align}
Initially we consider two GPs denoted by sqe\_1 and sqe\_2, whose hyperparameter values are described in table \ref{table:sqe hyperparameters}. Samples from the prior distributions of sqe\_1 and sqe\_1 are shown in figures \ref{fig:prior_sqe_1} and \ref{fig:prior_sqe_2}, which show that the prior distribution of sqe\_1 looks subjectively like a much more plausible explanation for the data. The predictive distributions of these GPs are shown in figures \ref{fig:pred_dist_sqe_1} and \ref{fig:pred_dist_sqe_2}, which show that, although sqe\_1 produced a \emph{prior} distribution which looks like a more plausible explanation for the training data, sqe\_2 produces a \emph{predictive} distribution which looks like a much better fit to the training data. Furthermore, the predictive distribution of sqe\_1 is "confidently wrong" (the mean is far away from the ground truth labels and with high certainty/low standard deviation) in regions containing ground truth labels but no training data, which would be a very undesirable property of a machine learning prediction model in a safety-critical context. Samples from the predictive distribution of both GPs are shown in figures \ref{fig:pred_samples_sqe_1} and \ref{fig:pred_samples_sqe_2}, which show that neither GP produces samples that reflect the data distribution particularly well.

The evaluation of GPs sqe\_1 and sqe\_2 according to the metrics RMSE (square root of the mean-squared-error between labels and the GP's predictive mean), LML, and log predictive likelihood (LPL, which is just the logarithm of equation \ref{eq:conditional distribution} given the expression for a multivariate Gaussian probability density function \cite{bishop2006pattern}), is summarised in table \ref{table:metrics}. Note that although sqe\_1 has a very low RMSE evaluated on the training data, it has an RMSE which is $30\times$ higher when evaluated on the ground truth data, which is to say that sqe\_1 overfits the training data very badly, which is reflected in its relatively bad LML and LPLs. sqe\_2 has worse RMSE on the training data than the sqe\_1, but better RMSE on the ground truth data, which is to say that sqe\_2 generalises better to unseen data (although it does so with low confidence/high uncertainty, as seen in sqe\_2's predictive samples in figure \ref{fig:pred_samples_sqe_2}), and this is reflected in the better LML and LPLs of sqe\_2.

As mentioned in section \ref{section:intro}, the LML can be used as an objective function to optimise the hyperparameters of a GP. Starting with sqe\_2 (because this GP has greater LML than sqe\_1), the parameters of this GP can be optimised using the L-BFGS-B algorithm \cite{wright1999numerical}, leading to a GP referred to as sqe\_opt, whose hyperparameter values are described in table \ref{table:sqe hyperparameters}, and whose evaluation metrics are described in table \ref{table:metrics}. Remarkably, sqe\_opt has worse RMSE on \emph{training} data than sqe\_1, but better RMSE on \emph{unseen} ground truth data. This implies that optimising RMSE on training data (which is often performed in machine learning) is not always a good approach, because an improvement in the RMSE on training data might lead to decreased predictive performance on unseen data (which is generally of greater importance in machine learning), and that where possible, a better approach might be to optimise LML instead. The sensitivity of the LML of sqe\_opt to its hyperparameters is shown in figure \ref{fig:sqe sensitivity}, which shows that sqe\_opt is very sensitive to large values of $\lambda$ and small values of $\sigma$. The predictive distribution of sqe\_opt is shown in figure \ref{fig:pred_samples_sqe_opt}.
