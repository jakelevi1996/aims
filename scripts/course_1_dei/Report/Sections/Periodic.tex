A periodic kernel for a GP can be defined as follows:
\begin{equation}
    K_\text{per}(x, x') = k \exp\left( -\frac{2}{\lambda} \left( \sin \left( \pi \frac{x-x'}{T} \right) \right)^2 \right) \label{eq:periodic kernel}
\end{equation}
We define a new GP with a periodic kernel, set its hyperparameters to be identical to those of sqe\_opt, except that $T=0.5$, and denote this GP as per\_1. We then optimise the LML of this GP with respect to its hyperparameters as before, leading to a GP denoted by per\_opt. The hyperparameters of both GPs are summarised in table \ref{table:per hyperparameters}, evaluation metrics are summarised in table \ref{table:metrics}, and the predictive distribution of per\_opt is shown in figure \ref{fig:pred_samples_per_opt}. We see that per\_1 has a very bad LML (worse than sqe\_2, but not as bad as sqe\_1), and that per\_opt has a LML which is better than sqe\_2, but not as good as sqe\_opt.

We note per\_opt learns a much greater value of the observation noise $\sigma$ than did sqe\_opt, and also, looking at figure \ref{fig:pred_samples_per_opt}, that the predictive standard deviation of per\_opt (shown as the red shaded region, which predicts the standard deviation of the unknown label $f*$ without observation noise) is very low, whereas the samples from the predictive distribution of per\_opt (which do include observation noise) are much noisier. We can understand this behaviour by considering the expression for the periodic kernel function (equation \ref{eq:periodic kernel}), and interpreting the behaviour in terms of epistemic uncertainty, described in section \ref{section:uncertainty}. To the periodic kernel, two training points might be separated by a long time lag, but if they are separated by an exact (or close to exact) integer multiple of the period $T$ then they will be interpreted by the periodic kernel as occuring at the same (or at a nearby) input location.

For the Sotonmet data considered here, the training data is spread over ten periods of high/low tide, but using the periodic kernel, this data would be processed in exactly the same way if all 917 training points were shifted by an integer multiple of the period to lie in the first half day, in which case we would would have a large number of training points all in a very close vicinity to each other. In section \ref{section:uncertainty}, we saw that the predictive uncertainty increases when the number of nearby data points decreases (this is epistemic uncertainty), and here we see the inverse effect, that the predictive uncertainty decreases when, from the perspective of the kernel, the effective number of nearby data points increases. This explains why per\_opt learns a very high value of $\sigma$: to compensate for the high certainty it has about the value of the underlying noiseless variable $f$, as a result of effectively observing a larger number of training points in the nearby vicinity.

The sensitivity of the LML of per\_opt to the period, $T$, is shown in figure \ref{fig:per sensitivity}, which shows that the LML is very sensitive to and sharply peaked around the optimal value of $T$. In general, it might be difficult for a gradient-based optimisation algorithm to find the optimal value of a hyperparameter when the LML is so sharply peaked. A possible solution to this problem would be to model the LML as a function of the hyperparameters using a second GP, and use Bayesian Optimisation \cite{snoek2012practical} to optimise the hyperparameters, but this raises the question of how to optimise the hyperparameters of the second GP. Clearly one cannot use a separate Bayesian Optimisation routine to optimise the hyperparameters of every GP without requiring an infinite number of GPs.
