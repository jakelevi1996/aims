Given any finite set $\mathcal{K}$ of valid GP kernel functions, we can define a new function $K'(x, x')$ whose output is equal the sum or the product of the outputs of all GP kernel functions in $\mathcal{K}$, and $K'(x, x')$ will also be a valid GP kernel function \cite{bishop2006pattern}. Sums and products of kernels correspond to the assumptions that covariance is dependent on similarity under any kernel in $\mathcal{K}$ or on similarity under all kernels in $\mathcal{K}$, respectively. This naturally leads us to consider two new kernel functions $K_\text{sum}$ and $K_\text{prod}$, equal to the sum and the product respectively of squared exponential and periodic kernels. These kernel functions are defined below in terms of their hyperparameters:
\begin{align}
    K_\text{sum}(x, x') &= k_{\text{sqe}} \exp\left( -\left( \frac{x - x'}{\lambda_{\text{sqe}}} \right)^2 \right) + k_{\text{per}} \exp\left( -\frac{2}{\lambda_{\text{per}}} \left( \sin \left( \pi \frac{x-x'}{T} \right) \right)^2 \right) \\
    K_\text{prod}(x, x') &= k_{\text{sqe}} \exp\left( -\left( \frac{x - x'}{\lambda_{\text{sqe}}} \right)^2 \right) \times k_{\text{per}} \exp\left( -\frac{2}{\lambda_{\text{per}}} \left( \sin \left( \pi \frac{x-x'}{T} \right) \right)^2 \right)
\end{align}
We define GPs sum\_1 and prod\_1, having the same hyperparameter values as the corresponding hyperparameters in sqe\_opt and per\_opt (tables \ref{table:sqe hyperparameters} and \ref{table:per hyperparameters}), except that we use the value of $\sigma$ used by per\_opt, since this is larger than the value of $\sigma$ used by sqe\_opt, and the LML of a GP is generally more sensitive to small values of $\sigma$ than large values, as demonstrated in figure \ref{fig:sqe noise}. We then optimise the hyperparameters of GPs sum\_1 and prod\_1, leading to GPs sum\_opt and prod\_opt, respectively. The hyperparameter values of these four GPs are shown in tables \ref{table:sum hyperparameters} and \ref{table:prod hyperparameters}, their evaluation metrics are shown in table \ref{table:metrics}, and the predictive distributions of sum\_opt and prod\_opt are shown in figures \ref{fig:pred_samples_sum_opt} and \ref{fig:pred_samples_prod_opt}, respectively. GP sum\_opt has the best LML out of all the GPs considered in this report, although interestingly prod\_opt has a better RMSE evaluated on unseen ground truth data. Regarding sqe\_1, the first GP considered in this report, no other GP considered has better RMSE evaluated on training data, or worse RMSE evaluated on unseen ground truth data, which highlights the problems associated with overfitting the training data, as discussed in section \ref{section:sqe}. Regarding predictive distributions, sum\_opt has the best combination of predicting the periodic nature of tide heights far from the training data, while also accurately modelling local variations in tide height.
