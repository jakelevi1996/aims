\subsection{Standard Form Of Convex Problems}
A convex optimisation problem is one in which the objective function $f_0(x)$ (defined in equation \ref{eq:optimisation problem}) is a convex function, and the feasible set $\mathcal{F}$ (defined in equation \ref{eq:feasible set}) is a convex set. In order for $\mathcal{F}$ to be a convex set, any inequality constraints must restrict $x$ to be in a convex subset of its domain, and any equality constraints must restrict $x$ to be in an affine subspace of its domain. Therefore, a convex optimisation problem in the form of equation \ref{eq:optimisation problem} is said to be a standard form convex optimisation problem if the objective function $f_0(x)$ is a convex function, all inequality constraint functions $f_i(x)$ are convex functions ($\forall i\in\{1, \hdots, m\}$), and all equality constraint functions $h_i(x)$ are affine functions ($\forall i\in\{1, \hdots, p\}$), in which case the problem is a convex optimisation problem. However, not all convex optimisation problems are in standard form, as the following example demonstrates:
\begin{equation}
\begin{aligned}
    \underset{x \in \mathbb{R}^2}{\text{Minimise}} \quad & x_1^2 + x_2^2 \\
    \text{Subject to} \quad & f_1(x) = \frac{x_1}{1 + x_2^2} \le 0 \\
    & h_1(x) = (x_1 + x_2)^2 = 0
\end{aligned} \label{eq:non standard convex problem}
\end{equation}
In this case, $f_1(x)$ is not a convex function, and $h_1(x)$ is not an affine function, therefore the problem is not a standard form convex optimisation problem, however the objective function is a convex function, and the feasible set defined by these constraints is a convex set:
\begin{align*}
    \frac{x_1}{1 + x_2^2} &\le 0 \\
    (\forall x_2 \in \mathbb{R}) \quad \frac{1}{1 + x_2^2} &> 0 \\
    \Rightarrow x_1 &\le 0 \\
    (x_1 + x_2)^2 &= 0 \\
    \Rightarrow x_1 + x_2 &= 0 \\
    \Rightarrow x_2 &= -x_1 \\
    \Rightarrow x_2 &\ge 0 \\
    \Rightarrow \mathcal{F} &= \{ x\in\mathbb{R}^2: x_1 \le 0 \quad \text{and} \quad x_2 = -x_1 \}
\end{align*}
Therefore the problem in equation \ref{eq:non standard convex problem} is equivalent to the following standard form convex optimisation problem (for which the primal optimal cost is clearly $0$, achieved when $x_1=x_2=0$):
\begin{align*}
    \underset{x \in \mathbb{R}^2}{\text{Minimise}} \quad & x_1^2 + x_2^2 \\
    \text{Subject to} \quad & f_1(x) = x_1 \le 0 \\
    & h_1(x) = x_1 + x_2 = 0
\end{align*}

\subsection{Hyperbolic Constraints And Second-Order Cones}
A second-order cone problem (SOCP) is an optimisation problem that has the following form (see \cite{boyd2004convex}, equation 4.36, page 156):
\begin{equation}
\begin{aligned}
    \underset{x \in \mathcal{X}}{\text{Minimise}} \quad & f^Tx \\
    \text{Subject to} \quad & \Vert A_ix + b_i \Vert_2 \le c_i^Tx + d_i \quad i\in\{1, \hdots, m\} \\
    & Fx = g
\end{aligned} \label{eq:SOCP}
\end{equation}
The following equivalence can be used to express several different types of problems as SOCPs, which holds for any $x \in \mathbb{R}^n$ and $y, z \in \mathbb{R}$ which satisfy $y>0$ and $z>0$:
\begin{equation}
    x^Tx \le yz \quad \Leftrightarrow \quad \left\Vert\begin{bmatrix}
        2x \\
        y - z
    \end{bmatrix}\right\Vert_2 \le y + z \label{eq:SOCP identity}
\end{equation}
This equivalence can be proved as follows:
\begin{align*}
    && \left\Vert\begin{bmatrix}
        2x \\
        y - z
    \end{bmatrix}\right\Vert_2 &= \sqrt{\begin{bmatrix}
        2x \\
        y - z
    \end{bmatrix}^T \begin{bmatrix}
        2x \\
        y - z
    \end{bmatrix}} \\
    && &= \sqrt{(2x)^T(2x) + (y-z)^2} \\
    && &= \sqrt{4x^T x + y^2 - 2yz + z^2} \\
    && 0 \le \left\Vert\begin{bmatrix}
        2x \\
        y - z
    \end{bmatrix}\right\Vert_2 &\le y + z \\
    \Leftrightarrow && 0 \le \sqrt{4x^T x + y^2 - 2yz + z^2} &\le y + z \\
    \Leftrightarrow && 4x^T x + y^2 - 2yz + z^2 &\le y^2 + 2yz + z^2 \\
    \Leftrightarrow && 4x^T x &\le 4yz \\
    \Leftrightarrow && x^T x &\le yz
\end{align*}
This equivalence can be used for example to show that the following optimisation problem, which can be interpreted as maximising a harmonic mean, is equivalent to a SOCP ($a_i^T$ refers to the $i$th row of $A$):
\begin{equation}
\begin{aligned}
    \underset{x}{\text{Maximise}} \quad & \left( \sum_{i=1}^{m}\left[ \frac{1}{a_i^T x - b_i} \right] \right)^{-1} \\
    \text{Subject to} \quad & Ax > b
\end{aligned}
\end{equation}
This equivalence can be demonstrated as follows ($\cong$ is used to denote equivalence between optimisation problems, $\textbf{0}$ in bold-face is used to denote an appropriately sized matrix or vector in which every element is equal to 0, $\textbf{1}$ in bold-face is used to denote an appropriately sized vector in which every element is equal to 1, and $e_i$ is used to denote the $i$th basis vector in which the $i$th element is equal to 1 and all other elements are equal to 0):
\begin{align*}
    \underset{x}{\text{Maximise}} \quad & \left( \sum_{i=1}^{m}\left[ \frac{1}{a_i^T x - b_i} \right] \right)^{-1} \\
    \text{Subject to} \quad & Ax > b \\ \\
    \cong \quad \underset{x}{\text{Minimise}} \quad & \sum_{i=1}^{m}\left[ \frac{1}{a_i^T x - b_i} \right] \\
    \text{Subject to} \quad & Ax > b \\ \\
    \cong \quad \underset{x, y}{\text{Minimise}} \quad & \textbf{1}^T y \\
    \text{Subject to} \quad & Ax > b \\
    & y_i(a_i^T x - b_i) = 1 \quad (\forall i) \\ \\
    \cong \quad \underset{x, y}{\text{Minimise}} \quad & \textbf{1}^T y \\
    \text{Subject to} \quad & y \ge 0 \\
    & y_i(a_i^T x - b_i) \ge 1 \quad (\forall i) \\ \\
    \cong \quad \underset{x, y}{\text{Minimise}} \quad & \textbf{1}^T y \\
    \text{Subject to} \quad & \Vert 0 \Vert_2 \le y_i \quad (\forall i) \\
    & \left\Vert\begin{bmatrix}
        2 \\
        y_i - a_i^T x + b_i
    \end{bmatrix}\right\Vert_2 \le y_i + a_i^T x - b_i \quad (\forall i) \\ \\
    \cong \quad \underset{x, y}{\text{Minimise}} \quad & \begin{bmatrix} \mathbf{0} \\ \mathbf{1} \end{bmatrix}^T \begin{bmatrix} x \\ y \end{bmatrix} \\
    \text{Subject to} \quad & \left\Vert\begin{bmatrix} \mathbf{0} & \mathbf{0} \\ \mathbf{0} & \mathbf{0} \end{bmatrix}\begin{bmatrix} x \\ y \end{bmatrix} + \begin{bmatrix} 0 \\ 0 \end{bmatrix} \right\Vert_2 \le \begin{bmatrix} \mathbf{0} \\ e_i \end{bmatrix}^T \begin{bmatrix} x \\ y \end{bmatrix} + 0 \quad (\forall i) \\
    & \left\Vert\begin{bmatrix} \mathbf{0} & \mathbf{0} \\ -a_i^T & e_i^T \end{bmatrix}\begin{bmatrix} x \\ y \end{bmatrix} + \begin{bmatrix} 2 \\ b_i \end{bmatrix} \right\Vert_2 \le \begin{bmatrix} a_i \\ e_i \end{bmatrix}^T \begin{bmatrix} x \\ y \end{bmatrix} - b_i \quad (\forall i)
\end{align*}
Which at last is in the form of a SOCP defined in equation \ref{eq:SOCP}.

The equivalence in equation \ref{eq:SOCP identity} can also be used to show that a similar problem which can be interpreted as maximising a geometric mean can be reformulated as a SOCP (assuming $m$ is a power of 2):
\begin{equation}
\begin{aligned}
    \underset{x}{\text{Maximise}} \quad & \left( \prod_{i=1}^{m}\left[ a_i^T x - b_i \right] \right)^{1/m} \\
    \text{Subject to} \quad & Ax > b
\end{aligned} \label{eq:geometric mean SOCP}
\end{equation}
The trick is to recursively define variables $t_{j, i}$ for $j\in\{1,\hdots,\log_2(m)\}$ as follows:
\begin{align*}
    t_{0, i} &= a_i^T x - b_i \\
    t_{j+1, i} &= \sqrt{(t_{j, 2i})(t_{j, 2i+1})} \\
    \Rightarrow \quad t_{j+1, i}^2 &\le (t_{j, 2i})(t_{j, 2i+1}) \\
    \Leftrightarrow \quad \left\Vert\begin{bmatrix}
        2t_{j+1, i} \\
        t_{j, 2i} - t_{j, 2i+1}
    \end{bmatrix}\right\Vert_2 &\le t_{j, 2i} + t_{j, 2i+1}
\end{align*}
The optimisation problem in equation \ref{eq:geometric mean SOCP} can therefore be expressed as an equivalent SOCP as follows:
\begin{equation}
\begin{aligned}
    \underset{x}{\text{Maximise}} \quad & t_{\log_2(m), 1} \\
    \text{Subject to} \quad & t_{0, i} = a_i^T x - b_i \quad & (\forall i) \\
    & t_{j, i} \ge 0 \quad & (\forall i)(\forall j \in \{0, \hdots, \log_2(m)\}) \\
    & \left\Vert\begin{bmatrix}
        2t_{j+1, i} \\
        t_{j, 2i} - t_{j, 2i+1}
    \end{bmatrix}\right\Vert_2 \le t_{j, 2i} + t_{j, 2i+1} \quad & (\forall i)(\forall j \in \{0, \hdots, \log_2(m-1)\}) \\
\end{aligned}
\end{equation}

\subsection{Support Functions} \label{section:support functions}
The support function $S_C$ of a set $C$ is defined as follows:
\begin{equation}
    S_C(y) = \underset{x\in C}{\sup}\left[ y^T x \right] \label{eq:support function}
\end{equation}
The support function $S_C$ is convex, regardless of whether $C$ is convex or not, which is proved below (the proof is similar to the proof that the Lagrangian dual function is concave, provided in appendix \ref{appendix:proof dual concave}). To start the proof, it is useful to define a variable $x^*\in\bar{C}$ (where $\bar{C}$ denotes the closure of the set $C$) which is chosen to satisfy the following equation, given $\lambda\in[0, 1]$, $y$, and $z$:
\begin{align*}
    \underset{x\in C}{\sup}\left[ \lambda y^T x + (1-\lambda) z^T x \right] &= \lambda y^T x^* + (1-\lambda) z^T x^* \\
    \Rightarrow & \begin{cases}
        \underset{x\in C}{\sup}\left[ y^T x \right] \ge y^T x^* \\
        \underset{x\in C}{\sup}\left[ z^T x \right] \ge z^T x^*
    \end{cases} \\
    \Rightarrow \lambda \underset{x\in C}{\sup}\left[ y^T x \right] + (1 - \lambda) \underset{x\in C}{\sup}\left[ z^T x \right] &\ge \lambda y^T x^* + (1 - \lambda) z^T x^* \\
    &= \underset{x\in C}{\sup}\left[ \lambda y^T x + (1-\lambda) z^T x \right] \\
    \Rightarrow (\forall y, z)(\forall\lambda\in[0, 1]) \quad \lambda S_C(y) + (1 - \lambda) S_C(z) &\ge S_C( \lambda y + (1 - \lambda) z )
\end{align*}
It can also be prooved that $S_C = S_{\text{conv}(C)}$, where $\text{conv}(C)$ is the convex hull of $C$, defined below:
\begin{equation}
    \text{conv}(C) = \left\{ x:(\exists\lambda\in[0, 1])(\exists a, b \in C) \quad x = \lambda a + (1 - \lambda) b \right\}
\end{equation}
To prove that $S_C(y) = S_{\text{conv}(C)}(y)$, it is useful to consider a point $x\in \text{conv}(C)$, which by definition can be expressed as a convex combination of points $a, b \in C$:
\begin{align*}
    (\forall x\in\text{conv}(C))(\exists \lambda\in[0, 1], a, b\in C) \quad x &= \lambda a + (1 - \lambda) b \\
    \Rightarrow(\forall y) \quad y^T x &= \lambda y^T a + (1 - \lambda) y^T b \\
    & \le \lambda \underset{a\in C}{\sup}\left[ y^T a \right] + (1 - \lambda) \underset{b\in C}{\sup}\left[ y^T b \right] \\
    &= \lambda S_C(y) + (1 - \lambda) S_C(y) \\
    &= S_C(y) \\
    \Rightarrow(\forall y) \quad \underset{x\in\text{conv}(C)}{\sup}\left[ y^T x \right] &\le S_C(y) \\
    \Rightarrow(\forall y) \quad S_{\text{conv}(C)}(y) &\le S_C(y) \\
\end{align*}
Therefore, for any $y$, $S_{\text{conv}(C)}(y)$ is always a lower bound on $S_C(y)$. Because $C \subseteq \text{conv}(C)$, from the definition of the support function in equation \ref{eq:support function}, we must also have that for any $y$, $S_{\text{conv}(C)}(y) \ge S_C(y)$, by inclusion. Therefore it follows that for any $y$, $S_{\text{conv}(C)}(y) = S_C(y)$, and therefore $S_{\text{conv}(C)} = S_C$.

\subsection{Largest-L Norm Of A Vector}
For any vector $x\in\mathbb{R}^n$, the notation $x_{[i]}$ is used to denote the element of $x$ with the $i$th largest magnitude, which implies the following ordering of the elements of $x$:
\begin{equation*}
    |x_{[1]}| \ge |x_{[2]}| \ge \hdots \ge |x_{[n]}| \ge 0
\end{equation*}
The largest-$L$ norm of $x$ is defined as follows:
\begin{equation}
    \Vert x \Vert_{[L]} = \sum_{i=1}^L{\Bigl[ \left\vert x_{[i]} \right\vert \Bigr]}
\end{equation}
It can be proved that $f(x) = \Vert x \Vert_{[L]}$ is a convex function. First, it is useful to define the permutation $\rho_x$ as the permutation which maps each integer $i\in\{1,\hdots,n\}$ to the $i$th largest element of $x$ (with ties broken arbitrarily):
\begin{align*}
    \rho_x: \{1,\hdots,n\} &\rightarrow \{1,\hdots,n\} \\
    x_{\rho_x(i)} &= x_{[i]} \\
    \Rightarrow \quad &\begin{cases}
        |x_{\rho_x(1)}| \ge |x_{\rho_x(2)}| \ge \hdots \ge |x_{\rho_x(n)}| \ge 0 \\
        \Vert x \Vert_{[L]} = \sum_{i=1}^L{\Bigl[ \left\vert x_{\rho_x(i)} \right\vert \Bigr]}
    \end{cases}
\end{align*}
For any permutation $\rho: \{1,\hdots,n\} \rightarrow \{1,\hdots,n\}$ besides $\rho_x$, the following inequality must hold:
\begin{equation*}
    \sum_{i=1}^L{\Bigl[ \left\vert x_{\rho_x(i)} \right\vert \Bigr]} \ge \sum_{i=1}^L{\Bigl[ \left\vert x_{\rho(i)} \right\vert \Bigr]}
\end{equation*}
To prove this inequality, assume that the inequality were violated, then it must be the case that $\rho(i)$ for $i\in\{1,\hdots,L\}$ selects the $L$ largest-in-magnitude elements of $x$, but $\rho_x$ does not, which contradicts the definition of $\rho_x$.

Similarly, for any vector $y\in\mathbb{R}^n$ and any scalar $\lambda\in[0, 1]$, it is useful to define the permutations $\rho_y$ and $\rho_{xy\lambda}$ on the integers $i\in\{1,\hdots,n\}$ as follows:
\begin{align*}
    x_{\rho_y(i)} &= y_{[i]} \\
    x_{\rho_{xy\lambda}(i)} &= (\lambda x + (1 - \lambda)y)_{[i]}
\end{align*}
Now it is straightforward to prove that $f(x) = \Vert x \Vert_{[L]}$ is a convex function, given any $x, y\in\mathbb{R}^n$ and any $\lambda\in[0, 1]$:
\begin{align*}
    \Vert \lambda x + (1 - \lambda)y \Vert_{[L]} &= \sum_{i=1}^L{\Bigl[ \left\vert (\lambda x + (1 - \lambda)y)_{[i]} \right\vert \Bigr]} \\
    &= \sum_{i=1}^L{\Bigl[ \left\vert (\lambda x + (1 - \lambda)y)_{\rho_{xy\lambda}(i)} \right\vert \Bigr]} \\
    &\le \lambda\sum_{i=1}^L{\Bigl[ \left\vert x_{\rho_{xy\lambda}(i)} \right\vert \Bigr]} + (1 - \lambda)\sum_{i=1}^L{\Bigl[ \left\vert y_{\rho_{xy\lambda}(i)} \right\vert \Bigr]} \\
    &\le \lambda\sum_{i=1}^L{\Bigl[ \left\vert x_{\rho_x(i)} \right\vert \Bigr]} + (1 - \lambda)\sum_{i=1}^L{\Bigl[ \left\vert y_{\rho_y(i)} \right\vert \Bigr]} \\
    &= \lambda\sum_{i=1}^L{\Bigl[ \left\vert x_{[i]} \right\vert \Bigr]} + (1 - \lambda)\sum_{i=1}^L{\Bigl[ \left\vert y_{[i]} \right\vert \Bigr]} \\
    &= \lambda\Vert x \Vert_{[L]} + (1 - \lambda)\Vert y \Vert_{[L]}
\end{align*}
This concludes the proof that $f(x) = \Vert x \Vert_{[L]}$ is convex.

The computation of $\Vert x \Vert_{[L]}$ for $x\in\mathbb{R}^N$ can be formulated as an integer programming problem as follows, where $(x_\text{abs})_i = \vert x_i \vert$:
\begin{align*}
    \underset{s\in\mathbb{Z}^N}{\text{Maximise}} \quad & x_\text{abs}^T s \\
    \text{Subject to} \quad & \mathbf{1}^Ts = L \\
    & s_i\in\{0, 1\} \quad (\forall i\in\{1, \hdots, n\})
\end{align*}
The computation of $\Vert x \Vert_{[L]}$ for $x\in\mathbb{R}^N$ can also be formulated as a linear program as follows:
\begin{align*}
    \underset{s\in\mathbb{R}^N}{\text{Maximise}} \quad & x_\text{abs}^T s \\
    \text{Subject to} \quad & \mathbf{1}^Ts = L \\
    & 0 \le s_i \le 1 \quad (\forall i\in\{1, \hdots, n\})
\end{align*}
The former approach can be interpreted as the support function of $x_\text{abs}$ over the set $S_\text{bin} = \left\{ s\in\{0,1\}^N:\mathbf{1}^T s = 1 \right\}$, and the latter approach can be interpreted as the support function of $x_\text{abs}$ over the set $S_\text{cont} = \left\{ s\in[0,1]^N:\mathbf{1}^T s = 1 \right\}$. The set $S_\text{cont}$ is the convex hull of the set $S_\text{bin}$, therefore the results of section \ref{section:support functions} imply that the two results should be equivalent.
