\subsection{Projection Onto The L1 Ball}
A point $a \in \mathbb{R}^N$ can be projected onto the unit ball in the $\ell_1$ norm by solving the following quadratic program:
\begin{align*}
    \underset{x}{\text{Minimise}} \quad & \frac{1}{2}\Vert x - a \Vert_2^2 \\
    \text{Subject to} \quad & \Vert x \Vert_1 \le c
\end{align*}
This is equivalent to the following quadratic program with slack variables $t$ introduced:
\begin{align*}
    \underset{x,t}{\text{Minimise}} \quad & \frac{1}{2}(x - a)^T(x - a) \\
    \text{Subject to} \quad & x \le t \\
    & x \ge -t \\
    & \mathbf{1}^T t \le c
\end{align*}
The Lagrangian and Lagrangian dual functions can be defined for this problem as follows:
\begin{align*}
    \mathcal{L}(x, t, \lambda) &= \frac{1}{2}(x - a)^T(x - a) + \lambda_1^T(x - t) + \lambda_2^T(-x - t) + \lambda_3(\mathbf{1}^T t - c) \\
    &= \frac{1}{2}x^Tx + (-a + \lambda_1 - \lambda_2)^T x + \frac{1}{2}a^Ta + (-\lambda_1 - \lambda_2 + \lambda_3\mathbf{1})^Tt - \lambda_3c \\
    \frac{\partial\mathcal{L}}{\partial x} &= x + (-a + \lambda_1 - \lambda_2) \\
    \frac{\partial\mathcal{L}}{\partial x} = 0 \quad &\Rightarrow \quad x = a - \lambda_1 + \lambda_2 \\
    &\Rightarrow \quad \mathcal{L}(x, t, \lambda) = -\frac{1}{2}(a - \lambda_1 + \lambda_2)^T(a - \lambda_1 + \lambda_2) + \frac{1}{2}a^Ta + (-\lambda_1 - \lambda_2 + \lambda_3\mathbf{1})^Tt - \lambda_3c \\
    g(\lambda) &= \underset{x, t}{\inf}\left[\mathcal{L}(x, t, \lambda)\right] \\
    &= \begin{cases}
        -\frac{1}{2}(a - \lambda_1 + \lambda_2)^T(a - \lambda_1 + \lambda_2) + \frac{1}{2}a^Ta - \lambda_3c \quad & -\lambda_1 - \lambda_2 + \lambda_3\mathbf{1} = 0 \\
        -\infty & \text{Otherwise}
    \end{cases}
\end{align*}
The dual problem in this case is equivalent to maximising the dual function $g(\lambda)$ with respect to $\lambda\ge0$, which can be expressed as the following quadratic program:
\begin{align*}
    \underset{\lambda_1, \lambda_2, \lambda_3}{\text{Maximise}} \quad & -\frac{1}{2}(a - \lambda_1 + \lambda_2)^T(a - \lambda_1 + \lambda_2) + \frac{1}{2}a^Ta - \lambda_3c \\
    \text{Subject to} \quad & -\lambda_1 - \lambda_2 + \lambda_3\mathbf{1} = 0 \\
    & \lambda_1 \ge 0 \\
    & \lambda_2 \ge 0 \\
    & \lambda_3 \ge 0
\end{align*}
The dual problem could be solved efficiently by using an interior point method, for example. From the solution to the dual problem, the optimal value for $x$ can be found easily as the value that minimises the Lagrangian function, where $\lambda_1$ and $\lambda_2$ represent the Lagrange multipliers for the inequality constraints $x \le t$ and $x \ge -t$ respectively:
\begin{equation*}
    x = a - \lambda_1 + \lambda_2
\end{equation*}

\subsection{SVM Duality}
A standard support vector machine problem can be expressed as follows:
\begin{equation*}
    \min_{a, b}{\left[ \sum_i{\Bigl[ \max{ \Bigl[ \{ 0, 1-s_i(a^Tv_i + b) \} \Bigl] } \Bigl]} + k\Vert a \Vert_2^2 \right]}
\end{equation*}
This problem can be expressed as a quadratic program by introducing the slack variables $t$, matrix $V$, and diagonal matrix $S$ as follows:
\begin{align*}
    V_{ij} = &(v_i)_j \\
    S_{ij} = &\begin{cases}
        s_i & i = j \\
        0 & i \ne j
    \end{cases} \\
    \Rightarrow \quad \underset{a, b, t}{\text{Maximise}} \quad & \mathbf{1}^T t + k a^T a \\
    & t \ge 0 \\
    & t \ge \mathbf{1} - S(Va + b\mathbf{1})
\end{align*}
The Lagrangian and Lagrangian dual functions can be defined for this problem as follows:
\begin{align*}
    \mathcal{L}(a, b, t, \lambda) &= \mathbf{1}^T t + k a^T a - \lambda_1^Tt + \lambda_2^T(\mathbf{1} - S(Va + b\mathbf{1}) - t) \\
    &= (\mathbf{1} - \lambda_1 - \lambda_2)^T t + ka^T a - \lambda_2^TSVa - \lambda_2^TS\mathbf{1}b + \lambda_2^T\mathbf{1} \\
    \frac{\partial\mathcal{L}}{\partial a} &= 2ka - V^TS\lambda_2 \\
    \frac{\partial\mathcal{L}}{\partial a} = 0 \quad &\Rightarrow \quad a = \frac{1}{2k}V^TS\lambda_2 \\
    &\Rightarrow \quad \mathcal{L}(a, b, t, \lambda) = (\mathbf{1} - \lambda_1 - \lambda_2)^T t -\frac{1}{4k}\lambda_2^TSVV^TS\lambda_2 - \lambda_2^TS\mathbf{1}b + \lambda_2^T\mathbf{1} \\
    g(\lambda) &= \underset{a, b, t}{\inf}\left[\mathcal{L}(a, b, t, \lambda)\right] \\
    &= \begin{cases}
        -\frac{1}{4k}\lambda_2^TSVV^TS\lambda_2 + \lambda_2^T\mathbf{1} \quad & \mathbf{1} - \lambda_1 - \lambda_2 = 0 \quad \text{and} \quad \lambda_2^TS\mathbf{1} = 0 \\
        -\infty & \text{Otherwise}
    \end{cases}
\end{align*}
The dual problem in this case is equivalent to maximising the dual function $g(\lambda)$ with respect to $\lambda\ge0$, which can be expressed as the following quadratic program:
\begin{align*}
    \underset{\lambda_1, \lambda_2, \lambda_3}{\text{Maximise}} \quad & -\frac{1}{4k}\lambda_2^TSVV^TS\lambda_2 + \lambda_2^T\mathbf{1} \\
    \text{Subject to} \quad & \mathbf{1} - \lambda_1 - \lambda_2 = 0 \\
    & \lambda_2^TS\mathbf{1} = 0 \\
    & \lambda_1 \ge 0 \\
    & \lambda_2 \ge 0 \\
    & \lambda_3 \ge 0
\end{align*}

\subsection{Adjustable Optimization}
